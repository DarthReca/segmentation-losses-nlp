num_train_epochs: 1
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
warmup_steps: 500
weight_decay: 0.01
logging_dir: "logs"
logging_steps: 10
evaluation_strategy: "steps"
save_strategy: "steps"
load_best_model_at_end: False
learning_rate: 1e-4
dataloader_num_workers: 4
save_total_limit: 3
use_cpu: False
# fp16: True
bf16: True
metric_for_best_model: "eval_question_answering_loss"
greater_is_better: False
eval_steps: 500
gradient_accumulation_steps: 2
optim: adamw
prediction_loss_only: True
losses:
  question_answering:
    cross_entropy: 0.6
    focal: 0.4
